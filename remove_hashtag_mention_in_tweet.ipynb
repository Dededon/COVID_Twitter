{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\aruba\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\aruba\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aruba\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aruba\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\aruba\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement urllib.parse (from versions: none)\n",
      "ERROR: No matching distribution found for urllib.parse\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rt(string):\n",
    "    return re.sub(r\"^RT @\\w \", \"\", string)\n",
    "\n",
    "# From \"@musicmadmarc @SocialDilemma_ @netflix @Facebook I'm also reminded of the very poignant quote by French philosopher… https://t.co/CA52aepW6K\"\n",
    "# to: \"I'm also reminded of the very poignant quote by French philosopher… https://t.co/CA52aepW6K\"\n",
    "\n",
    "def remove_beginning_mentions(string):\n",
    "#     print(string)\n",
    "#     if(re.search(r'@\\w+',string) != None):\n",
    "    # if(string =='@'):\n",
    "    new_string=re.sub(r'^[@\\w ]*','',string,1)\n",
    "    new_string = new_string.strip()\n",
    "    string = remove_beginning_mentions(new_string)\n",
    "    return string\n",
    "\n",
    "# From \"#musicmadmarc #SocialDilemma_ #netflix #Facebook I'm also reminded of the very poignant quote by French philosopher… https://t.co/CA52aepW6K\"\n",
    "# to: \"I'm also reminded of the very poignant quote by French philosopher… https://t.co/CA52aepW6K\"\n",
    "\n",
    "def remove_beginning_hashs(string):\n",
    "    # if(string[0]=='#'):\n",
    "    new_string=re.sub(r'^[#\\w ]*','',string,1)\n",
    "    new_string = new_string.strip()\n",
    "    string = remove_beginning_mentions(new_string)\n",
    "    return string\n",
    "\n",
    "# From \" I'm also reminded of the very poignant quote by French philosopher… https://t.co/CA52aepW6K @musicmadmarc @SocialDilemma_ @netflix @Facebook\"\n",
    "# to: \"I'm also reminded of the very poignant quote by French philosopher… https://t.co/CA52aepW6K\"\n",
    "\n",
    "def remove_last_mentions(string):\n",
    "    last_mention = string.rfind('@')\n",
    "    last_space = string.rfind(' ')\n",
    "    if(last_mention > last_space):\n",
    "        string = string[:last_space]\n",
    "        string = remove_last_mentions(string)\n",
    "    return string\n",
    "\n",
    "# From \" I'm also reminded of the very poignant quote by French philosopher… https://t.co/CA52aepW6K @musicmadmarc @SocialDilemma_ @netflix @Facebook\"\n",
    "# to: \"I'm also reminded of the very poignant quote by French philosopher… https://t.co/CA52aepW6K\"\n",
    "\n",
    "def remove_last_hashs(string):\n",
    "    last_mention = string.rfind('#')\n",
    "    last_space = string.rfind(' ')\n",
    "    if(last_mention > last_space):\n",
    "        string = string[:last_space]\n",
    "        string = remove_last_mentions(string)\n",
    "    return string\n",
    "\n",
    "def remove_punctuation_notation(string):\n",
    "    string = re.sub(r'[\\$%&\\'()*+\\-\\/=#@\\[\\\\\\]^_`{|}~]*','',string)\n",
    "    return string\n",
    "\n",
    "def preprocessing_pipeline(string):\n",
    "    string = remove_rt(string)\n",
    "    string = remove_beginning_mentions(string)\n",
    "    string = remove_beginning_hashs(string)\n",
    "    string = remove_last_mentions(string)\n",
    "    string = remove_last_hashs(string)\n",
    "    string = remove_punctuation_notation(string)\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aruba\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\aruba\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (7,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "mask = pd.read_csv('./output/mask_text.csv')\n",
    "vaccine = pd.read_csv('./output/vaccine_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "# Input the t.co format url and return the original link\n",
    "def to_source_url(shorturl):\n",
    "    try:\n",
    "        r = requests.get(shorturl)\n",
    "        src = urlsplit(r.url)[1]\n",
    "        return src\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def find_url(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(vaccine['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really love that shirt at\n",
      "Titanic tragedy could have been prevented Economic Times Telegraph co ukTitanic tragedy could have been preve\n",
      "I am at Starbucks 7419 3rd ave at 75th Brooklyn\n"
     ]
    }
   ],
   "source": [
    "def strip_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')    \n",
    "    return text\n",
    "\n",
    "def strip_all_entities(text):\n",
    "    entity_prefixes = ['@','#','RT @']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "tests = [\n",
    "    \"@peter I really love that shirt at #Macy. http://bet.ly//WjdiW4\",\n",
    "    \"@shawn Titanic tragedy could have been prevented Economic Times: Telegraph.co.ukTitanic tragedy could have been preve... http://bet.ly/tuN2wx\",\n",
    "    \"I am at Starbucks http://4sh.com/samqUI (7419 3rd ave, at 75th, Brooklyn)\",\n",
    "]\n",
    "for t in tests:\n",
    "    print(strip_all_entities(strip_links(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(vaccine['text'])\n",
    "filtered = []\n",
    "urls = []\n",
    "for t in text:\n",
    "    result = find_url(t)\n",
    "    url_list = []\n",
    "    for r in result:\n",
    "        url_list.append(r[0])\n",
    "    urls.append(url_list)    \n",
    "    cleared_text = strip_links(t)\n",
    "    cleared_text = strip_all_entities(cleared_text)\n",
    "    filtered.append(cleared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccine['filtered text'] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_url = []\n",
    "for url_list in urls:\n",
    "    src_list = []\n",
    "    for url in url_list:\n",
    "        src_list.append(to_source_url(url))\n",
    "    src_url.append(src_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccine['src_url'] = src_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccine.to_csv('./output/filtered_vaccine_text.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "f36458b81b9c378f43f2f4e4ca80e8aaf260acc6ac27b27c70b16ecb01255b39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
